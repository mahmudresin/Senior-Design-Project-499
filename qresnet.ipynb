{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from resfile.resnet import resnet18\n",
    "from evaluate import evaluate\n",
    "model= None\n",
    "model = resnet18()\n",
    "#print(model)\n",
    "modules_to_list = model.modules_to_fuse()\n",
    "# This will fuse BatchNorm weights into the preceding Conv\n",
    "fused_model = torch.ao.quantization.fuse_modules(resnet18, modules_to_list)\n",
    "\n",
    "# Assigning qconfigs\n",
    "from torch.ao.quantization.fake_quantize import FakeQuantize\n",
    "activation_qconfig = FakeQuantize.with_args(\n",
    "    observer=torch.ao.quantization.observer.HistogramObserver.with_args(\n",
    "        quant_min=0,\n",
    "        quant_max=255,\n",
    "        dtype=torch.quint8,\n",
    "        qscheme=torch.per_tensor_affine,\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_qconfig = FakeQuantize.with_args(\n",
    "    observer=torch.ao.quantization.observer.PerChannelMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=torch.qint8,\n",
    "        qscheme=torch.per_channel_symmetric,\n",
    "    )\n",
    ")\n",
    "\n",
    "qconfig = torch.quantization.QConfig(activation=activation_qconfig,\n",
    "                                      weight=weight_qconfig)\n",
    "fused_model.qconfig = qconfig\n",
    "\n",
    "#  Prepare for fake-quant\n",
    "fused_model.train()\n",
    "fake_quant_model = torch.ao.quantization.prepare_qat(fused_model)\n",
    "\n",
    "print(\"\\nFused Model\")\n",
    "evaluate(fused_model, 'cpu')\n",
    "\n",
    "print(\"\\nFake quant - PTQ\")\n",
    "evaluate(fake_quant_model, 'cpu')\n",
    "\n",
    "fake_quant_model.apply(torch.ao.quantization.fake_quantize.disable_observer)\n",
    "\n",
    "print(\"\\nFake quant - post-PTQ\")\n",
    "evaluate(fake_quant_model, 'cpu')\n",
    "\n",
    "converted_model = torch.ao.quantization.convert(fake_quant_model)\n",
    "\n",
    "print(\"\\nConverted model\")\n",
    "evaluate(converted_model, 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
