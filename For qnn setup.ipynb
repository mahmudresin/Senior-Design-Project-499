{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 9588433,
          "sourceType": "datasetVersion",
          "datasetId": 5847681
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook382fdf734f",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahmudresin/Senior-Design-Project-499/blob/main/For%20qnn%20setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'experimental:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5847681%2F9588433%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241013%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241013T121241Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4790da4b5b5c0251b5b0cbe2e52aab2e9056a1a7e58a7016ec8e554f3d4ed0a7e5d8bcd0aef2a1975082ae098d4d019e84f4d5c9f60234e97e6848a4ac95031967bf6c8e1c3335d65d888ea3814381740b9679f450711e20b1493bc13a64dea231a6a0d4b2447b49bc217a847418041dfee6d62b46b3c02327d2b4aa6c3aae056507ebae2b0abebd96fd46277a3fde1fa13ac5349043035c61e73a2bd0dc523221143880dc605c7a64e682d942a478375162fcd791dc25c38483cfd580bbaa2da21ade5624ade32644fdba06b569cde81ef7f0ce4d889f4b1fe3d5aa3be1d3201f0dbb562544beed0e07e64ac3f582a13e3f41fdaa924f1e915bf00445163715'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryu_MPFS277C",
        "outputId": "35848cf1-998b-4516-d40e-114cff75d2fd"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading experimental, 649517303 bytes compressed\n",
            "[==================================================] 649517303 bytes downloaded\n",
            "Downloaded and uncompressed: experimental\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from fastai.imports import *\n",
        "from fastai.vision.all import *\n",
        "import PIL\n",
        "import os\n",
        "import torch  # Import torch for GPU management\n",
        "\n",
        "# Function to enable GPU if available\n",
        "def enable_gpu_if_available():\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU is available.\")\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        print(\"GPU is not available; using CPU instead.\")\n",
        "        return torch.device('cpu')\n",
        "\n",
        "# Function to cleanup GPU cache\n",
        "def cleanup_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()  # Free up unused memory on the GPU\n",
        "        print(\"GPU cache cleaned.\")\n",
        "    else:\n",
        "        print(\"No GPU found; nothing to clean.\")\n",
        "\n",
        "# Custom utility functions (make sure utils directory is correctly set up)\n",
        "try:\n",
        "    from utils.utils import *\n",
        "except ModuleNotFoundError as e:\n",
        "    print(f\"Error: {e}. Please check if the 'utils' module is available in your path.\")\n",
        "\n",
        "# Ensure proper output display in Jupyter\n",
        "from IPython.display import clear_output, DisplayHandle\n",
        "\n",
        "def update_patch(self, obj):\n",
        "    clear_output(wait=True)\n",
        "    self.display(obj)\n",
        "\n",
        "# Environment variable setup for Weights & Biases (wandb)\n",
        "os.environ[\"ENABLE_WANDB\"] = \"ON\"\n",
        "\n",
        "if os.getenv(\"ENABLE_WANDB\"):\n",
        "    g_ENABLE_WANDB = True\n",
        "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"ai4mars.ipynb\"\n",
        "    import wandb\n",
        "    from fastai.callback.wandb import *\n",
        "\n",
        "    wandb.login()\n",
        "    wandb.init(project=\"AI4Mars\")\n",
        "else:\n",
        "    g_ENABLE_WANDB = False\n",
        "\n",
        "# Update the DisplayHandle with the custom output patch\n",
        "DisplayHandle.update = update_patch\n",
        "\n",
        "# Enable GPU if available\n",
        "g_DEVICE = enable_gpu_if_available()\n",
        "cleanup_gpu_cache()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:27:32.549189Z",
          "iopub.execute_input": "2024-10-09T18:27:32.549601Z",
          "iopub.status.idle": "2024-10-09T18:27:37.511367Z",
          "shell.execute_reply.started": "2024-10-09T18:27:32.549562Z",
          "shell.execute_reply": "2024-10-09T18:27:37.510371Z"
        },
        "trusted": true,
        "id": "QuDtEid8277J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the paths to our images and labels."
      ],
      "metadata": {
        "id": "79S4Ful3277K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base dataset path\n",
        "dataset_path = Path('/kaggle/input/experimental/Experimental Data')\n",
        "\n",
        "# Define the paths for images and masks\n",
        "IMAGES_PATH = Path(dataset_path / \"images\" )\n",
        "MASK_PATH_TRAIN = Path(dataset_path /  \"train\")\n",
        "MASK_PATH_TEST = Path(dataset_path /  \"test\" )\n",
        "\n",
        "#len(IMAGES_PATH.ls()), len(MASK_PATH_TRAIN.ls()), len(MASK_PATH_TEST.ls())"
      ],
      "metadata": {
        "trusted": true,
        "id": "RdTEOQcs277K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from fastai.imports import *\n",
        "from fastai.vision.all import *\n",
        "import PIL\n",
        "import os\n",
        "import torch\n",
        "from pathlib import Path  # Import Path for handling file paths\n",
        "\n",
        "# Define the path to your dataset\n",
        "dataset_path = Path('/path/to/mars_dataset')  # Replace with the actual path to your dataset\n",
        "\n",
        "# Define image and mask paths\n",
        "IMAGES_PATH = Path(dataset_path / \"images\")\n",
        "MASK_PATH_TRAIN = Path(dataset_path / \"train\")\n",
        "MASK_PATH_TEST = Path(dataset_path / \"test\")\n",
        "\n",
        "# Function to prepare the dataset\n",
        "def prepare_dataset(images_path, mask_path_train, mask_path_test):\n",
        "    # This is a placeholder implementation. You should implement the logic to prepare your dataset here.\n",
        "    images_train = []  # Logic to load training images\n",
        "    images_test = []   # Logic to load test images\n",
        "    images_unused = [] # Logic to load unused images\n",
        "\n",
        "    # Example: Loading images (you need to implement this according to your dataset structure)\n",
        "    # images_train = [Image.open(img) for img in images_path.glob('train/*.png')]  # Example code\n",
        "    # images_test = [Image.open(img) for img in images_path.glob('test/*.png')]    # Example code\n",
        "\n",
        "    return images_train, images_test, images_unused\n",
        "\n",
        "# Function to enable GPU if available\n",
        "def enable_gpu_if_available():\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU is available.\")\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        print(\"GPU is not available; using CPU instead.\")\n",
        "        return torch.device('cpu')\n",
        "\n",
        "# Function to cleanup GPU cache\n",
        "def cleanup_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()  # Free up unused memory on the GPU\n",
        "        print(\"GPU cache cleaned.\")\n",
        "    else:\n",
        "        print(\"No GPU found; nothing to clean.\")\n",
        "\n",
        "# Custom utility functions (make sure utils directory is correctly set up)\n",
        "try:\n",
        "    from utils.utils import *\n",
        "except ModuleNotFoundError as e:\n",
        "    print(f\"Error: {e}. Please check if the 'utils' module is available in your path.\")\n",
        "\n",
        "# Ensure proper output display in Jupyter\n",
        "from IPython.display import clear_output, DisplayHandle\n",
        "\n",
        "def update_patch(self, obj):\n",
        "    clear_output(wait=True)\n",
        "    self.display(obj)\n",
        "\n",
        "# Environment variable setup for Weights & Biases (wandb)\n",
        "os.environ[\"ENABLE_WANDB\"] = \"ON\"\n",
        "\n",
        "if os.getenv(\"ENABLE_WANDB\"):\n",
        "    g_ENABLE_WANDB = True\n",
        "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"ai4mars.ipynb\"\n",
        "    import wandb\n",
        "    from fastai.callback.wandb import *\n",
        "\n",
        "    wandb.login()\n",
        "    wandb.init(project=\"AI4Mars\")\n",
        "else:\n",
        "    g_ENABLE_WANDB = False\n",
        "\n",
        "# Update the DisplayHandle with the custom output patch\n",
        "DisplayHandle.update = update_patch\n",
        "\n",
        "# Enable GPU if available\n",
        "g_DEVICE = enable_gpu_if_available()\n",
        "cleanup_gpu_cache()\n",
        "\n",
        "# Prepare dataset\n",
        "IMAGES_PATH_TRAIN, IMAGES_PATH_TEST, IMAGES_PATH_UNUSED = prepare_dataset(\n",
        "    IMAGES_PATH, MASK_PATH_TRAIN, MASK_PATH_TEST\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:34:24.807892Z",
          "iopub.execute_input": "2024-10-09T18:34:24.80829Z",
          "iopub.status.idle": "2024-10-09T18:34:29.776992Z",
          "shell.execute_reply.started": "2024-10-09T18:34:24.808252Z",
          "shell.execute_reply": "2024-10-09T18:34:29.775838Z"
        },
        "trusted": true,
        "id": "a1Ig8rcu277L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane\n",
        "from fastai.vision.all import *\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "dataset_path = Path('/kaggle/input/experimental/Experimental Data')\n",
        "# Define image and mask paths\n",
        "IMAGES_PATH = Path(dataset_path / \"images\")\n",
        "MASK_PATH_TRAIN = Path(dataset_path / \"train\")\n",
        "MASK_PATH_TEST = Path(dataset_path / \"test\")\n",
        "\n",
        "# Load images and masks\n",
        "def load_images_and_masks(image_path, mask_path, size=(128, 128)):\n",
        "    images = get_image_files(image_path)\n",
        "    masks = get_image_files(mask_path)\n",
        "\n",
        "    # Ensure sorted order (in case filenames are not in order)\n",
        "    images.sort()\n",
        "    masks.sort()\n",
        "\n",
        "    image_data = []\n",
        "    mask_data = []\n",
        "\n",
        "    # Loop over each image and mask to resize and add to list\n",
        "    for img_file, mask_file in zip(images, masks):\n",
        "        img = PILImage.create(img_file)\n",
        "        mask = PILImage.create(mask_file)\n",
        "\n",
        "        # Resize\n",
        "        img = img.resize(size)\n",
        "        mask = mask.resize(size)\n",
        "\n",
        "        # Convert to tensor and normalize\n",
        "        img_tensor = tensor(img) / 255.0\n",
        "        mask_tensor = tensor(mask) / 255.0\n",
        "\n",
        "        image_data.append(img_tensor)\n",
        "        mask_data.append(mask_tensor)\n",
        "\n",
        "    return torch.stack(image_data), torch.stack(mask_data)\n",
        "\n",
        "train_images, train_masks = load_images_and_masks(IMAGES_PATH, MASK_PATH_TRAIN)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:13:46.22489Z",
          "iopub.execute_input": "2024-10-10T07:13:46.225354Z",
          "iopub.status.idle": "2024-10-10T07:16:07.859265Z",
          "shell.execute_reply.started": "2024-10-10T07:13:46.225312Z",
          "shell.execute_reply": "2024-10-10T07:16:07.857627Z"
        },
        "trusted": true,
        "id": "pQhnzCC3277L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of qubits (depending on image size)\n",
        "n_qubits = 4  # Can be adjusted\n",
        "\n",
        "# Quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Quantum circuit\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs):\n",
        "    # Encode classical data into quantum states\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(inputs[i], wires=i)  # Rotation along X-axis (can be adjusted)\n",
        "\n",
        "    # Apply quantum operations\n",
        "    for i in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "\n",
        "    # Measurement\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "# Example of encoding data (you would typically pass the image data here)\n",
        "data_example = torch.tensor([0.1, 0.2, 0.3, 0.4], requires_grad=True)\n",
        "output = quantum_circuit(data_example)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:16:14.83753Z",
          "iopub.execute_input": "2024-10-10T07:16:14.838051Z",
          "iopub.status.idle": "2024-10-10T07:16:14.991955Z",
          "shell.execute_reply.started": "2024-10-10T07:16:14.837997Z",
          "shell.execute_reply": "2024-10-10T07:16:14.990589Z"
        },
        "trusted": true,
        "id": "rRAqiKH9277L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class HybridQuantumClassicalModel(nn.Module):\n",
        "    def __init__(self, n_qubits, n_output):\n",
        "        super(HybridQuantumClassicalModel, self).__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_output = n_output\n",
        "\n",
        "        # Define a classical fully connected layer\n",
        "        self.fc1 = nn.Linear(n_qubits, 64)\n",
        "        self.fc2 = nn.Linear(64, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Assume x is a batch of quantum-encoded inputs\n",
        "        quantum_output = []\n",
        "\n",
        "        # Pass each input through the quantum circuit\n",
        "        for i in range(x.shape[0]):\n",
        "            q_out = quantum_circuit(x[i])\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        quantum_output = torch.stack(quantum_output)\n",
        "\n",
        "        # Pass the quantum circuit output through classical layers\n",
        "        x = torch.relu(self.fc1(quantum_output))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "model = HybridQuantumClassicalModel(n_qubits=n_qubits, n_output=1)  # Output 1 for regression/classification\n",
        "output = model(data_example.unsqueeze(0))  # Adding a batch dimension\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:16:38.707374Z",
          "iopub.execute_input": "2024-10-10T07:16:38.707812Z",
          "iopub.status.idle": "2024-10-10T07:16:39.176283Z",
          "shell.execute_reply.started": "2024-10-10T07:16:38.707771Z",
          "shell.execute_reply": "2024-10-10T07:16:39.174373Z"
        },
        "trusted": true,
        "id": "-qXMQznk277L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "\n",
        "class HybridQuantumClassicalModel(nn.Module):\n",
        "    def __init__(self, n_qubits, n_output):\n",
        "        super(HybridQuantumClassicalModel, self).__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_output = n_output\n",
        "\n",
        "        # Define a classical fully connected layer\n",
        "        self.fc1 = nn.Linear(n_qubits, 64)\n",
        "        self.fc2 = nn.Linear(64, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Assume x is a batch of quantum-encoded inputs\n",
        "        quantum_output = []\n",
        "\n",
        "        # Pass each input through the quantum circuit\n",
        "        for i in range(x.shape[0]):\n",
        "            q_out = quantum_circuit(x[i])  # Returns a tensor from the quantum circuit\n",
        "            q_out = torch.tensor(q_out, dtype=torch.float32)  # Ensure it's a tensor\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        # Stack the quantum outputs into a single tensor\n",
        "        quantum_output = torch.stack(quantum_output)\n",
        "\n",
        "        # Pass the quantum circuit output through classical layers\n",
        "        x = torch.relu(self.fc1(quantum_output))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Quantum circuit\n",
        "dev = qml.device(\"default.qubit\", wires=4)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs):\n",
        "    # Encode classical data into quantum states\n",
        "    for i in range(4):  # Assuming 4 qubits\n",
        "        qml.RX(inputs[i], wires=i)\n",
        "\n",
        "    # Apply quantum operations (for example, CNOT gates)\n",
        "    for i in range(3):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "\n",
        "    # Return the expectation values of the Pauli-Z operator for each qubit\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(4)]  # Returns a list of 4 values\n",
        "\n",
        "# Example usage\n",
        "n_qubits = 4  # Number of qubits\n",
        "model = HybridQuantumClassicalModel(n_qubits=n_qubits, n_output=1)\n",
        "\n",
        "# Example input data (with a batch dimension)\n",
        "data_example = torch.tensor([[0.1, 0.2, 0.3, 0.4]], requires_grad=True)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(data_example)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:18:55.299887Z",
          "iopub.execute_input": "2024-10-10T07:18:55.300436Z",
          "iopub.status.idle": "2024-10-10T07:18:55.347109Z",
          "shell.execute_reply.started": "2024-10-10T07:18:55.300389Z",
          "shell.execute_reply": "2024-10-10T07:18:55.345759Z"
        },
        "trusted": true,
        "id": "1a1HXXAU277M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class HybridQuantumClassicalModel(nn.Module):\n",
        "    def __init__(self, n_qubits, n_output):\n",
        "        super(HybridQuantumClassicalModel, self).__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_output = n_output\n",
        "\n",
        "        # Define a classical fully connected layer\n",
        "        self.fc1 = nn.Linear(n_qubits, 64)\n",
        "        self.fc2 = nn.Linear(64, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Assume x is a batch of quantum-encoded inputs\n",
        "        quantum_output = []\n",
        "\n",
        "        # Pass each input through the quantum circuit\n",
        "        for i in range(x.shape[0]):\n",
        "            q_out = quantum_circuit(x[i])\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        quantum_output = torch.stack(quantum_output)\n",
        "\n",
        "        # Pass the quantum circuit output through classical layers\n",
        "        x = torch.relu(self.fc1(quantum_output))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "model = HybridQuantumClassicalModel(n_qubits=n_qubits, n_output=1)  # Output 1 for regression/classification\n",
        "output = model(data_example.unsqueeze(0))  # Adding a batch dimension\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:19:49.758223Z",
          "iopub.execute_input": "2024-10-10T07:19:49.758798Z",
          "iopub.status.idle": "2024-10-10T07:19:50.454841Z",
          "shell.execute_reply.started": "2024-10-10T07:19:49.758741Z",
          "shell.execute_reply": "2024-10-10T07:19:50.452606Z"
        },
        "trusted": true,
        "id": "bs0NRB0R277M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "\n",
        "class HybridQuantumClassicalModel(nn.Module):\n",
        "    def __init__(self, n_qubits, n_output):\n",
        "        super(HybridQuantumClassicalModel, self).__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_output = n_output\n",
        "\n",
        "        # Define a classical fully connected layer\n",
        "        self.fc1 = nn.Linear(n_qubits, 64)\n",
        "        self.fc2 = nn.Linear(64, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Assume x is a batch of quantum-encoded inputs\n",
        "        quantum_output = []\n",
        "\n",
        "        # Pass each input through the quantum circuit\n",
        "        for i in range(x.shape[0]):\n",
        "            q_out = quantum_circuit(x[i])\n",
        "            q_out = torch.tensor(q_out, dtype=torch.float32)\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        # Stack the quantum outputs into a single tensor\n",
        "        quantum_output = torch.stack(quantum_output)\n",
        "\n",
        "        # Pass the quantum circuit output through classical layers\n",
        "        x = torch.relu(self.fc1(quantum_output))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Define the quantum circuit\n",
        "dev = qml.device(\"default.qubit\", wires=4)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs):\n",
        "    # Encode classical data into quantum states\n",
        "    for i in range(4):  # Assuming 4 qubits\n",
        "        qml.RX(inputs[i], wires=i)  # Use RX gate for rotation on each qubit\n",
        "\n",
        "    # Apply quantum operations (for example, CNOT gates)\n",
        "    for i in range(3):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "\n",
        "    # Return the expectation values of the Pauli-Z operator for each qubit\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(4)]  # Return a list of 4 values\n",
        "\n",
        "# Example usage:\n",
        "n_qubits = 4  # Number of qubits in the quantum circuit\n",
        "model = HybridQuantumClassicalModel(n_qubits=n_qubits, n_output=1)\n",
        "\n",
        "# Example input data (batch size = 1, matching number of qubits)\n",
        "data_example = torch.tensor([[0.1, 0.2, 0.3, 0.4]], requires_grad=True)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(data_example)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:21:46.524959Z",
          "iopub.execute_input": "2024-10-10T07:21:46.526352Z",
          "iopub.status.idle": "2024-10-10T07:21:46.553565Z",
          "shell.execute_reply.started": "2024-10-10T07:21:46.526297Z",
          "shell.execute_reply": "2024-10-10T07:21:46.552161Z"
        },
        "trusted": true,
        "id": "z0uLGRSu277M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()  # You can adjust the loss function depending on the task\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop (simplified)\n",
        "for epoch in range(10):  # Number of epochs\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(train_images)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, train_masks)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:23:10.821616Z",
          "iopub.execute_input": "2024-10-10T07:23:10.822135Z",
          "iopub.status.idle": "2024-10-10T07:23:12.15278Z",
          "shell.execute_reply.started": "2024-10-10T07:23:10.822065Z",
          "shell.execute_reply": "2024-10-10T07:23:12.150602Z"
        },
        "trusted": true,
        "id": "tTwrGDzi277N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()  # Adjust depending on your task\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Modify the quantum circuit to ensure it processes one sample at a time\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    qml.BasisState(x, wires=range(n_qubits))\n",
        "    qml.RX(x[0], wires=0)  # Expecting a scalar for RX\n",
        "    # Add more quantum gates as needed\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):  # Number of epochs\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Loop through each sample in the training data (batch processing)\n",
        "    quantum_output = []\n",
        "    for i in range(train_images.shape[0]):\n",
        "        # Ensure input shape is correct for quantum circuit (e.g., single sample)\n",
        "        x_sample = train_images[i].squeeze()  # Flatten the image if needed\n",
        "        x_sample = torch.tensor(x_sample, dtype=torch.float32)\n",
        "\n",
        "        # Forward pass through the quantum circuit\n",
        "        q_out = quantum_circuit(x_sample)\n",
        "        q_out = torch.tensor(q_out, dtype=torch.float32)\n",
        "        quantum_output.append(q_out)\n",
        "\n",
        "    # Convert list of quantum outputs to a tensor\n",
        "    output = torch.stack(quantum_output)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, train_masks)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:25:46.654903Z",
          "iopub.execute_input": "2024-10-10T07:25:46.655503Z",
          "iopub.status.idle": "2024-10-10T07:25:46.845785Z",
          "shell.execute_reply.started": "2024-10-10T07:25:46.655411Z",
          "shell.execute_reply": "2024-10-10T07:25:46.844036Z"
        },
        "trusted": true,
        "id": "rgqHzkvt277N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pennylane as qml\n",
        "\n",
        "# Set the number of qubits in your quantum circuit\n",
        "n_qubits = 4  # Example number, adjust based on your task\n",
        "\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    # Flatten the input so it becomes one-dimensional\n",
        "    x_flat = x.flatten()\n",
        "\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x_flat) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x_flat)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # Process through quantum gates\n",
        "    qml.BasisState(x_flat, wires=range(n_qubits))  # Pass flattened input to BasisState\n",
        "    qml.RX(x_flat[0], wires=0)  # Example of an RX gate\n",
        "    # Add more quantum gates as needed\n",
        "\n",
        "    # Return an expectation value as an output\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Assuming you have a batch of samples to process\n",
        "quantum_output = []\n",
        "\n",
        "for x_sample in x_train_batch:  # Assuming x_train_batch is your input batch\n",
        "    # Convert sample to a tensor if needed and flatten it\n",
        "    x_sample = torch.tensor(x_sample, dtype=torch.float32).flatten()\n",
        "\n",
        "    # Forward pass through the quantum circuit\n",
        "    q_out = quantum_circuit(x_sample)\n",
        "    q_out = torch.tensor(q_out, dtype=torch.float32)\n",
        "    quantum_output.append(q_out)\n",
        "\n",
        "quantum_output = torch.stack(quantum_output)  # Combine into a tensor for further processing\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:28:14.049632Z",
          "iopub.execute_input": "2024-10-10T07:28:14.050304Z",
          "iopub.status.idle": "2024-10-10T07:28:14.126255Z",
          "shell.execute_reply.started": "2024-10-10T07:28:14.050243Z",
          "shell.execute_reply": "2024-10-10T07:28:14.12393Z"
        },
        "trusted": true,
        "id": "YxfYRiyh277N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Define number of qubits based on the input\n",
        "n_qubits = 128  # Update this based on your quantum circuit's design\n",
        "\n",
        "# Define the quantum circuit\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    # Flatten the input so it becomes one-dimensional\n",
        "    x_flat = x.flatten()\n",
        "\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x_flat) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x_flat)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # BasisState preparation\n",
        "    qml.BasisState(x_flat, wires=range(n_qubits))\n",
        "\n",
        "    # Example quantum gates (customize as needed)\n",
        "    qml.RX(x_flat[0], wires=0)  # Rotate qubit 0 around X-axis\n",
        "    qml.RY(x_flat[1], wires=1)  # Rotate qubit 1 around Y-axis\n",
        "    # Add more quantum gates as necessary\n",
        "\n",
        "    # Measure an observable (for example, PauliZ on qubit 0)\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define your PyTorch model\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        # Classical layers (example: one linear layer)\n",
        "        self.fc1 = nn.Linear(4, n_qubits)  # Adjust input size and output size\n",
        "\n",
        "    def forward(self, x):\n",
        "        quantum_output = []\n",
        "\n",
        "        # Process each sample in the batch\n",
        "        for x_sample in x:\n",
        "            # Ensure the input is a float tensor\n",
        "            x_sample = torch.tensor(x_sample, dtype=torch.float32)\n",
        "\n",
        "            # Flatten the input if it has multiple dimensions\n",
        "            x_sample = x_sample.flatten()\n",
        "\n",
        "            # Forward pass through the quantum circuit\n",
        "            q_out = quantum_circuit(x_sample.detach().numpy())  # Use numpy array for Pennylane\n",
        "            q_out = torch.tensor(q_out, dtype=torch.float32)  # Convert quantum output back to tensor\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        # Stack the quantum outputs and return\n",
        "        quantum_output = torch.stack(quantum_output)\n",
        "        return quantum_output\n",
        "\n",
        "# Example usage\n",
        "model = QuantumNet()\n",
        "\n",
        "# Example batch input (adjust size as needed)\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:28:36.458248Z",
          "iopub.execute_input": "2024-10-10T07:28:36.458848Z",
          "iopub.status.idle": "2024-10-10T07:28:36.735492Z",
          "shell.execute_reply.started": "2024-10-10T07:28:36.458791Z",
          "shell.execute_reply": "2024-10-10T07:28:36.733371Z"
        },
        "trusted": true,
        "id": "o4vfZJ3R277N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    x_flat = x.flatten()\n",
        "\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x_flat) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x_flat)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # BasisState preparation\n",
        "    qml.BasisState(x_flat, wires=range(n_qubits))\n",
        "\n",
        "    # Example quantum gates (can be modified)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(x_flat[i], wires=i)\n",
        "\n",
        "    # Return expectation value of PauliZ on the first qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16, n_qubits)  # Adjust for the flattened size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Preprocess the input\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Resize the image to match the number of qubits (e.g., 16x16)\n",
        "        x = F.interpolate(x, size=(16, 16))  # Resize to 16x16\n",
        "\n",
        "        # Flatten the image\n",
        "        x = x.view(-1, 16 * 16 * 16)  # Match the input size to the fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        quantum_output = []\n",
        "        for x_sample in x:\n",
        "            x_sample = x_sample.flatten().detach().numpy()  # Flatten and convert to numpy for Pennylane\n",
        "\n",
        "            # Forward pass through the quantum circuit\n",
        "            q_out = quantum_circuit(x_sample)\n",
        "            q_out = torch.tensor(q_out, dtype=torch.float32)  # Convert quantum output back to tensor\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        quantum_output = torch.stack(quantum_output)  # Combine into a tensor\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:29:40.309592Z",
          "iopub.execute_input": "2024-10-10T07:29:40.310948Z",
          "iopub.status.idle": "2024-10-10T07:29:40.718074Z",
          "shell.execute_reply.started": "2024-10-10T07:29:40.310895Z",
          "shell.execute_reply": "2024-10-10T07:29:40.716197Z"
        },
        "trusted": true,
        "id": "j5L8-9Uh277O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    x_flat = x.flatten()\n",
        "\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x_flat) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x_flat)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # BasisState preparation\n",
        "    qml.BasisState(x_flat, wires=range(n_qubits))\n",
        "\n",
        "    # Example quantum gates (can be modified)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(x_flat[i], wires=i)\n",
        "\n",
        "    # Return expectation value of PauliZ on the first qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16, n_qubits)  # Adjust for the flattened size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input to the correct format (batch_size, channels, height, width)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Preprocess the input\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Resize the image to match the number of qubits (e.g., 16x16)\n",
        "        x = F.interpolate(x, size=(16, 16))  # Resize to 16x16\n",
        "\n",
        "        # Flatten the image\n",
        "        x = x.view(-1, 16 * 16 * 16)  # Match the input size to the fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        quantum_output = []\n",
        "        for x_sample in x:\n",
        "            x_sample = x_sample.flatten().detach().numpy()  # Flatten and convert to numpy for Pennylane\n",
        "\n",
        "            # Forward pass through the quantum circuit\n",
        "            q_out = quantum_circuit(x_sample)\n",
        "            q_out = torch.tensor(q_out, dtype=torch.float32)  # Convert quantum output back to tensor\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        quantum_output = torch.stack(quantum_output)  # Combine into a tensor\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:30:38.416466Z",
          "iopub.execute_input": "2024-10-10T07:30:38.416936Z",
          "iopub.status.idle": "2024-10-10T07:30:38.72432Z",
          "shell.execute_reply.started": "2024-10-10T07:30:38.416892Z",
          "shell.execute_reply": "2024-10-10T07:30:38.722316Z"
        },
        "trusted": true,
        "id": "c8YoQhvf277O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    x_flat = x.flatten()\n",
        "\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x_flat) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x_flat)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # BasisState preparation\n",
        "    qml.BasisState(x_flat, wires=range(n_qubits))\n",
        "\n",
        "    # Example quantum gates (can be modified)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(x_flat[i], wires=i)\n",
        "\n",
        "    # Return expectation value of PauliZ on the first qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16, n_qubits)  # Adjust for the flattened size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input to the correct format (batch_size, channels, height, width)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Preprocess the input\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Resize the image to match the number of qubits (e.g., 16x16)\n",
        "        x = F.interpolate(x, size=(16, 16))  # Resize to 16x16\n",
        "\n",
        "        # Flatten the image\n",
        "        x = x.reshape(-1, 16 * 16 * 16)  # Use reshape instead of view\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        quantum_output = []\n",
        "        for x_sample in x:\n",
        "            x_sample = x_sample.flatten().detach().numpy()  # Flatten and convert to numpy for Pennylane\n",
        "\n",
        "            # Forward pass through the quantum circuit\n",
        "            q_out = quantum_circuit(x_sample)\n",
        "            q_out = torch.tensor(q_out, dtype=torch.float32)  # Convert quantum output back to tensor\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        quantum_output = torch.stack(quantum_output)  # Combine into a tensor\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:31:32.220976Z",
          "iopub.execute_input": "2024-10-10T07:31:32.221525Z",
          "iopub.status.idle": "2024-10-10T07:31:32.577593Z",
          "shell.execute_reply.started": "2024-10-10T07:31:32.221479Z",
          "shell.execute_reply": "2024-10-10T07:31:32.571877Z"
        },
        "trusted": true,
        "id": "3C9vPPLI277O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    x_flat = x.flatten()\n",
        "\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x_flat) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x_flat)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # Threshold the values to create a binary input\n",
        "    binary_x = (x_flat > 0.5).astype(int)\n",
        "\n",
        "    # BasisState preparation\n",
        "    qml.BasisState(binary_x, wires=range(n_qubits))\n",
        "\n",
        "    # Example quantum gates (can be modified)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(binary_x[i], wires=i)\n",
        "\n",
        "    # Return expectation value of PauliZ on the first qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16, n_qubits)  # Adjust for the flattened size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input to the correct format (batch_size, channels, height, width)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Preprocess the input\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Resize the image to match the number of qubits (e.g., 16x16)\n",
        "        x = F.interpolate(x, size=(16, 16))  # Resize to 16x16\n",
        "\n",
        "        # Flatten the image\n",
        "        x = x.reshape(-1, 16 * 16 * 16)  # Use reshape instead of view\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        quantum_output = []\n",
        "        for x_sample in x:\n",
        "            x_sample = x_sample.flatten().detach().numpy()  # Flatten and convert to numpy for Pennylane\n",
        "\n",
        "            # Forward pass through the quantum circuit\n",
        "            q_out = quantum_circuit(x_sample)\n",
        "            q_out = torch.tensor(q_out, dtype=torch.float32)  # Convert quantum output back to tensor\n",
        "            quantum_output.append(q_out)\n",
        "\n",
        "        quantum_output = torch.stack(quantum_output)  # Combine into a tensor\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:32:45.126049Z",
          "iopub.execute_input": "2024-10-10T07:32:45.126633Z",
          "iopub.status.idle": "2024-10-10T07:32:45.883782Z",
          "shell.execute_reply.started": "2024-10-10T07:32:45.126585Z",
          "shell.execute_reply": "2024-10-10T07:32:45.881179Z"
        },
        "trusted": true,
        "id": "UIdPCWXG277O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # Threshold the values to create a binary input\n",
        "    binary_x = (x > 0.5).astype(int)\n",
        "\n",
        "    # BasisState preparation\n",
        "    qml.BasisState(binary_x, wires=range(n_qubits))\n",
        "\n",
        "    # Example quantum gates (can be modified)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(binary_x[i], wires=i)\n",
        "\n",
        "    # Return expectation value of PauliZ on the first qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16, n_qubits)  # Adjust for the flattened size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input to the correct format (batch_size, channels, height, width)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Preprocess the input\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Flatten the image and pass through the fully connected layer\n",
        "        x = x.view(-1, 16 * 16 * 16)  # Reshape to (batch_size, 16*16*16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Initialize quantum output\n",
        "        quantum_output = torch.zeros(x.size(0))\n",
        "\n",
        "        # Forward pass through the quantum circuit for each sample in the batch\n",
        "        for i in range(x.size(0)):\n",
        "            x_sample = x[i].detach().numpy()  # Convert to numpy for Pennylane\n",
        "            q_out = quantum_circuit(x_sample)  # Forward pass through the quantum circuit\n",
        "            quantum_output[i] = torch.tensor(q_out, dtype=torch.float32)  # Store the result\n",
        "\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:34:47.664848Z",
          "iopub.execute_input": "2024-10-10T07:34:47.665517Z",
          "iopub.status.idle": "2024-10-10T07:34:47.850305Z",
          "shell.execute_reply.started": "2024-10-10T07:34:47.665456Z",
          "shell.execute_reply": "2024-10-10T07:34:47.848411Z"
        },
        "trusted": true,
        "id": "9Cjf3l5V277O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    # Ensure the input matches the number of qubits\n",
        "    if len(x) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    # Threshold the values to create a binary input\n",
        "    binary_x = (x > 0.5).astype(int)\n",
        "\n",
        "    # BasisState preparation\n",
        "    qml.BasisState(binary_x, wires=range(n_qubits))\n",
        "\n",
        "    # Example quantum gates (can be modified)\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(binary_x[i], wires=i)\n",
        "\n",
        "    # Return expectation value of PauliZ on the first qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 32 * 32, n_qubits)  # Adjust for the flattened size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input to the correct format (batch_size, channels, height, width)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Preprocess the input\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Flatten the image and pass through the fully connected layer\n",
        "        x = x.view(x.size(0), -1)  # Reshape to (batch_size, features)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Initialize quantum output\n",
        "        quantum_output = torch.empty(x.size(0), dtype=torch.float32)  # Preallocate output tensor\n",
        "\n",
        "        # Forward pass through the quantum circuit for each sample\n",
        "        for i in range(x.size(0)):\n",
        "            x_sample = x[i].detach().numpy()  # Convert to numpy for Pennylane\n",
        "\n",
        "            # Forward pass through the quantum circuit\n",
        "            q_out = quantum_circuit(x_sample)\n",
        "            quantum_output[i] = torch.tensor(q_out, dtype=torch.float32)  # Convert quantum output back to tensor\n",
        "\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:35:30.806586Z",
          "iopub.execute_input": "2024-10-10T07:35:30.807074Z",
          "iopub.status.idle": "2024-10-10T07:35:31.003279Z",
          "shell.execute_reply.started": "2024-10-10T07:35:30.807026Z",
          "shell.execute_reply": "2024-10-10T07:35:31.001308Z"
        },
        "trusted": true,
        "id": "uuD5Ea2Q277P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    if len(x) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    binary_x = (x > 0.5).astype(int)\n",
        "    qml.BasisState(binary_x, wires=range(n_qubits))\n",
        "\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(binary_x[i], wires=i)\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, n_qubits)  # Adjusted for the output size after pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input to the correct format (batch_size, channels, height, width)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Convolution and pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Flatten the output and pass through the fully connected layer\n",
        "        x = x.reshape(x.size(0), -1)  # Changed to reshape\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Initialize quantum output\n",
        "        quantum_output = torch.empty(x.size(0), dtype=torch.float32)  # Preallocate output tensor\n",
        "\n",
        "        # Forward pass through the quantum circuit for each sample\n",
        "        for i in range(x.size(0)):\n",
        "            x_sample = x[i].detach().numpy()  # Convert to numpy for Pennylane\n",
        "            q_out = quantum_circuit(x_sample)  # Forward pass through the quantum circuit\n",
        "            quantum_output[i] = torch.tensor(q_out, dtype=torch.float32)  # Convert back to tensor\n",
        "\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:36:24.663718Z",
          "iopub.execute_input": "2024-10-10T07:36:24.664242Z",
          "iopub.status.idle": "2024-10-10T07:36:25.238847Z",
          "shell.execute_reply.started": "2024-10-10T07:36:24.664194Z",
          "shell.execute_reply": "2024-10-10T07:36:25.236181Z"
        },
        "trusted": true,
        "id": "T05oZCZM277P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "import torch.nn.functional as F\n",
        "\n",
        "n_qubits = 128  # Set the number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    \"\"\"Process input through the quantum circuit.\"\"\"\n",
        "    # Ensure the input is of size n_qubits\n",
        "    if len(x) != n_qubits:\n",
        "        raise ValueError(f\"Input size {len(x)} does not match the number of qubits {n_qubits}\")\n",
        "\n",
        "    binary_x = (x > 0.5).astype(int)  # Convert to binary\n",
        "    qml.BasisState(binary_x, wires=range(n_qubits))\n",
        "\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(binary_x[i], wires=i)\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Define a hybrid quantum-classical neural network\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantumNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, n_qubits)  # Adjusted for the output size after pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Permute the input to the correct format (batch_size, channels, height, width)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Convolution and pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Flatten the output and pass through the fully connected layer\n",
        "        x = x.reshape(x.size(0), -1)  # Changed to reshape\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Initialize quantum output\n",
        "        quantum_output = torch.empty(x.size(0), dtype=torch.float32)  # Preallocate output tensor\n",
        "\n",
        "        # Forward pass through the quantum circuit for each sample\n",
        "        for i in range(x.size(0)):\n",
        "            x_sample = x[i][:n_qubits].detach().numpy()  # Convert to numpy for Pennylane, limit to n_qubits\n",
        "            q_out = quantum_circuit(x_sample)  # Forward pass through the quantum circuit\n",
        "            quantum_output[i] = torch.tensor(q_out, dtype=torch.float32)  # Convert back to tensor\n",
        "\n",
        "        return quantum_output\n",
        "\n",
        "# Create an instance of the model\n",
        "model = QuantumNet()\n",
        "\n",
        "# Simulate input data\n",
        "x = torch.rand(2, 128, 128, 3)  # Simulating a batch of 2 samples, with shape (128, 128, 3)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-10T07:37:13.326034Z",
          "iopub.execute_input": "2024-10-10T07:37:13.326721Z",
          "iopub.status.idle": "2024-10-10T07:37:13.896874Z",
          "shell.execute_reply.started": "2024-10-10T07:37:13.32666Z",
          "shell.execute_reply": "2024-10-10T07:37:13.893997Z"
        },
        "trusted": true,
        "id": "MwJS2vSq277P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare the dataset\n",
        "def prepare_dataset(images_path, mask_path_train, mask_path_test):\n",
        "    # Get lists of training and testing image paths\n",
        "    images_train = list(images_path.glob('train/*.png'))  # Replace with your actual image file extension\n",
        "    images_test = list(images_path.glob('test/*.png'))    # Replace with your actual image file extension\n",
        "\n",
        "    # Get lists of training and testing mask paths\n",
        "    masks_train = list(mask_path_train.glob('*.png'))  # Replace with your actual mask file extension\n",
        "    masks_test = list(mask_path_test.glob('*.png'))    # Replace with your actual mask file extension\n",
        "\n",
        "    return images_train, masks_train  # Return only the train images and masks\n",
        "\n",
        "# Prepare dataset\n",
        "IMAGES_PATH_TRAIN, MASK_PATH_TRAIN = prepare_dataset(\n",
        "    IMAGES_PATH, MASK_PATH_TRAIN, MASK_PATH_TEST\n",
        ")\n",
        "\n",
        "# Assert lengths directly\n",
        "assert len(IMAGES_PATH_TRAIN) == len(MASK_PATH_TRAIN), \"Training images and masks count do not match.\"\n",
        "\n",
        "print(type(IMAGES_PATH_TRAIN))  # Should be <class 'list'>\n",
        "print(type(MASK_PATH_TRAIN))     # Should be <class 'list'>\n",
        "print(len(IMAGES_PATH_TRAIN), len(MASK_PATH_TRAIN))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:36:21.25186Z",
          "iopub.execute_input": "2024-10-09T18:36:21.252914Z",
          "iopub.status.idle": "2024-10-09T18:36:21.265017Z",
          "shell.execute_reply.started": "2024-10-09T18:36:21.252852Z",
          "shell.execute_reply": "2024-10-09T18:36:21.263709Z"
        },
        "trusted": true,
        "id": "DKJaGM0G277P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize an Image\n",
        "\n",
        "Now that we have the data downloaded, we can proceed with actually visualizing some of the images and masks that we have.\n",
        "\n",
        "Lets start by first seeing what one of these images looks like."
      ],
      "metadata": {
        "id": "6BD617NA277Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = PILImage.create(IMAGES_PATH_TRAIN.ls()[2])\n",
        "img.show(figsize=(5, 5))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:37:39.547972Z",
          "iopub.execute_input": "2024-10-09T18:37:39.548502Z",
          "iopub.status.idle": "2024-10-09T18:37:39.590275Z",
          "shell.execute_reply.started": "2024-10-09T18:37:39.548452Z",
          "shell.execute_reply": "2024-10-09T18:37:39.588699Z"
        },
        "trusted": true,
        "id": "NJpAjPpq277Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of images in the training set\n",
        "num_images = len(IMAGES_PATH_TRAIN)\n",
        "print(f\"Number of training images: {num_images}\")\n",
        "\n",
        "# Use a valid index\n",
        "if num_images > 2:  # Check if there are at least 3 images\n",
        "    img_index = 2\n",
        "    img = PILImage.create(IMAGES_PATH_TRAIN[img_index])  # Access the image by index\n",
        "    img.show()  # Show the image\n",
        "else:\n",
        "    print(\"Not enough images available to access index 2.\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:40:10.45596Z",
          "iopub.execute_input": "2024-10-09T18:40:10.4572Z",
          "iopub.status.idle": "2024-10-09T18:40:10.465834Z",
          "shell.execute_reply.started": "2024-10-09T18:40:10.457139Z",
          "shell.execute_reply": "2024-10-09T18:40:10.464816Z"
        },
        "trusted": true,
        "id": "FFlii1Jn277Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize a Mask"
      ],
      "metadata": {
        "id": "hGWBi1T_277Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, to see the corresponding mask associated with our image, we'll need a small function to help us map them on\n",
        "the fly. According to the AI4Mars info.txt file, the images end with extension `.JPG` while the corresponding label\n",
        "ends with `.png`."
      ],
      "metadata": {
        "id": "6WEJ24sm277R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_mask_path = lambda file: MASK_PATH_TRAIN / f\"{file.stem}.png\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:40:14.292206Z",
          "iopub.execute_input": "2024-10-09T18:40:14.292731Z",
          "iopub.status.idle": "2024-10-09T18:40:14.298769Z",
          "shell.execute_reply.started": "2024-10-09T18:40:14.292679Z",
          "shell.execute_reply": "2024-10-09T18:40:14.29733Z"
        },
        "trusted": true,
        "id": "itWxRR8g277R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_mask = PILMask.create(get_mask_path(IMAGES_PATH_TRAIN.ls()[2]))\n",
        "example_mask.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:40:16.219665Z",
          "iopub.execute_input": "2024-10-09T18:40:16.220076Z",
          "iopub.status.idle": "2024-10-09T18:40:16.256596Z",
          "shell.execute_reply.started": "2024-10-09T18:40:16.220038Z",
          "shell.execute_reply": "2024-10-09T18:40:16.254928Z"
        },
        "trusted": true,
        "id": "XPHNbt8-277R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Engineering"
      ],
      "metadata": {
        "id": "9Shi_mwo277R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In semantic segmentation, the “labels” are a 1:1 mask of the original picture with each pixel representing a label and are single channel:"
      ],
      "metadata": {
        "id": "IEeaqWN2277R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor(example_mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:40:18.868726Z",
          "iopub.execute_input": "2024-10-09T18:40:18.869717Z",
          "iopub.status.idle": "2024-10-09T18:40:18.904665Z",
          "shell.execute_reply.started": "2024-10-09T18:40:18.869661Z",
          "shell.execute_reply": "2024-10-09T18:40:18.902946Z"
        },
        "trusted": true,
        "id": "7puRY-7d277R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very quickly we see an issue!\n",
        "\n",
        "Because of how the loss gets calculated (and how fastai does things in general), the values of the pixel mask must be from 0 -> n, with n being the number of classes possible. If we take things as they are here during training you’ll hit an error that says “CUDA Segmentation Fault, Index Out of Bounds” (or something similar).\n",
        "\n",
        "This is because our labels should be from 0 -> 4, to align with the fact predicted probabilities from our model are 0 -> 4. Instead they are 0, 1, 2, 3 and 255, leading to this issue.\n",
        "\n",
        "So how do we fix the issue? In numpy we can just override the numbers for a particular value in the array and set it. To generalize this however a dictionary of the original value to the new one should also be made:"
      ],
      "metadata": {
        "id": "GNtSBlmB277S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_codes = {0: 0, 1: 1, 2: 2, 3: 3, 4: 255}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.074685Z",
          "iopub.status.idle": "2024-10-09T18:21:30.075056Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.074878Z",
          "shell.execute_reply": "2024-10-09T18:21:30.074897Z"
        },
        "trusted": true,
        "id": "YDtWHAMA277S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to create a get_y function. In this case it should take in a filename and our dictionary, open the filename, and return the mask:"
      ],
      "metadata": {
        "id": "VQ4H8ILy277S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(filename: Path, unique_codes: dict) -> PILMask:\n",
        "    filename = get_mask_path(filename)\n",
        "    mask_array = np.asarray(PIL.Image.open(filename)).copy()\n",
        "\n",
        "    mask_array[mask_array == 255] = 4\n",
        "\n",
        "    return PILMask.create(mask_array)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.076327Z",
          "iopub.status.idle": "2024-10-09T18:21:30.076689Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.076512Z",
          "shell.execute_reply": "2024-10-09T18:21:30.076531Z"
        },
        "trusted": true,
        "id": "newR6Cqv277S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets stop check this now."
      ],
      "metadata": {
        "id": "41wNKCoL277S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor(get_label(IMAGES_PATH_TRAIN.ls()[2], unique_codes))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.077489Z",
          "iopub.status.idle": "2024-10-09T18:21:30.077867Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.07766Z",
          "shell.execute_reply": "2024-10-09T18:21:30.077678Z"
        },
        "trusted": true,
        "id": "w6j6M5JH277S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask: PILMask = get_label(IMAGES_PATH_TRAIN.ls()[2], unique_codes)\n",
        "mask.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.078771Z",
          "iopub.status.idle": "2024-10-09T18:21:30.079142Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.078969Z",
          "shell.execute_reply": "2024-10-09T18:21:30.078988Z"
        },
        "trusted": true,
        "id": "wMm7MAf5277S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect!"
      ],
      "metadata": {
        "id": "uz0TQcsA277T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next thing we should do is create a list of our codes that map to the corresponding pixel value. According to the\n",
        "info.txt, the codes are as follows:\n",
        "\n",
        "| RGB         | Key             |\n",
        "|-------------|-----------------|\n",
        "| 0,0,0       | soil            |\n",
        "| 1,1,1       | bedrock         |\n",
        "| 2,2,2       | sand            |\n",
        "| 3,3,3       | big rock        |\n",
        "| 255,255,255 -> 4, 4, 4 | NULL (no label) |"
      ],
      "metadata": {
        "id": "s3mKYyvy277T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codes = np.array([\"soil\", \"bedrock\", \"sand\", \"big rock\", \"null\"], dtype=str)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.080449Z",
          "iopub.status.idle": "2024-10-09T18:21:30.080854Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.080645Z",
          "shell.execute_reply": "2024-10-09T18:21:30.080664Z"
        },
        "trusted": true,
        "id": "c3u6GzLa277T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Our `DataLoader`"
      ],
      "metadata": {
        "id": "kMrySJFx277T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now everything is in place to create our `DataBlock` object. Jeremy Howard, the founder of Fast.AI, popularized the idea of image resizing:\n",
        "\n",
        "* Train on smaller sized images\n",
        "* Eventually get larger and larger\n",
        "* Transfer Learning loop\n",
        "\n",
        "In the AI4Mars paper, the authors mention that they resize their images to 512x512 from the original 1024x1024 size.\n",
        "\n",
        "Since I am training on a laptop GPU, I will resize the images to 256x256."
      ],
      "metadata": {
        "id": "66S2S8RQ277T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_sizes = mask.shape\n",
        "mask_sizes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.082624Z",
          "iopub.status.idle": "2024-10-09T18:21:30.083014Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.082829Z",
          "shell.execute_reply": "2024-10-09T18:21:30.082849Z"
        },
        "trusted": true,
        "id": "zFK04ysr277T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_sizes = tuple(int(x / 4) for x in mask_sizes)\n",
        "mask_sizes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.084014Z",
          "iopub.status.idle": "2024-10-09T18:21:30.084357Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.084185Z",
          "shell.execute_reply": "2024-10-09T18:21:30.084202Z"
        },
        "trusted": true,
        "id": "t6Q4ChTH277T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the AI4Mars paper, the authors mention that the \"batch size was chosen to be as large as possible before running into GPU memory issues\". We will do the same."
      ],
      "metadata": {
        "id": "2yvW5Rua277U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataBlock(\n",
        "    blocks=(\n",
        "        ImageBlock,\n",
        "        MaskBlock(codes=codes),\n",
        "    ),  # our input is an image and outpus is a mask\n",
        "    splitter=RandomSplitter(),  # randomly split our dataset into 80% train and 20% valid\n",
        "    get_y=partial(get_label, unique_codes=unique_codes),  # load our preprocessed labels\n",
        "    batch_tfms=[\n",
        "        *aug_transforms(size=mask_sizes),\n",
        "        Normalize.from_stats(*imagenet_stats),\n",
        "    ],  # apply some standard augs\n",
        ").dataloaders(get_image_files(IMAGES_PATH_TRAIN), bs=8)\n",
        "\n",
        "data_loader.show_batch()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.086376Z",
          "iopub.status.idle": "2024-10-09T18:21:30.086721Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.086552Z",
          "shell.execute_reply": "2024-10-09T18:21:30.086569Z"
        },
        "trusted": true,
        "id": "1kx1jo9x277U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Our Model Architecture\n",
        "\n",
        "Next, we can create our `Learner` object that will wrap our model architecture, hyperparameters, and `DataLoader` into one abstract object.\n",
        "\n",
        "In the AI4Mars paper, the authors opted for the DeepLabv3+ model architecture with a ResNet-101 backend pretrained on ImageNet. For our architecture, we will go with a U-Net with a ResNet-34 backing that's been pre-trained on ImageNet. We _could_ utilize a fancy modern vision transformer, however, with spacecraft you want technology that is tried and true. U-Net has a long and rich history that make it a reliable model architecture for our purposes.\n",
        "\n",
        "![U-Net Diagram](./../img/u_net_arch.png \"U-Net Architecture Diagram\")"
      ],
      "metadata": {
        "id": "cly8wROe277U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets define our U-Net architecture with the ResNet-18 backbone. The metrics\n",
        "we use are the accuracy and mIoU. Our loss function is the CrossEntropyLoss.\n",
        "The optimizer is good ol' Adam."
      ],
      "metadata": {
        "id": "eI4nNuMy277U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleanup_gpu_cache()\n",
        "\n",
        "learner = unet_learner(\n",
        "    data_loader,\n",
        "    resnet18,\n",
        "    metrics=[partial(foreground_acc, bkg_idx=4), JaccardCoeffMulti()],\n",
        "    loss_func=CrossEntropyLossFlat(axis=1),\n",
        "    opt_func=Adam,\n",
        "    norm_type=None,\n",
        "    wd_bn_bias=True,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.088467Z",
          "iopub.status.idle": "2024-10-09T18:21:30.088836Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.088642Z",
          "shell.execute_reply": "2024-10-09T18:21:30.088659Z"
        },
        "trusted": true,
        "id": "GeIgfMf7277U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what our model architecture looks like."
      ],
      "metadata": {
        "id": "plTvR_bR277U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.090067Z",
          "iopub.status.idle": "2024-10-09T18:21:30.090407Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.090238Z",
          "shell.execute_reply": "2024-10-09T18:21:30.090255Z"
        },
        "trusted": true,
        "id": "ff-SvRJu277U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per our requirements, our model **must** fit under the imposed limit. Lets check and make sure we are meeting our requirement."
      ],
      "metadata": {
        "id": "CcZpIqZp277V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert calc_model_size(learner.model) <= 200.0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.091655Z",
          "iopub.status.idle": "2024-10-09T18:21:30.09203Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.091849Z",
          "shell.execute_reply": "2024-10-09T18:21:30.091868Z"
        },
        "trusted": true,
        "id": "aqIYDJCj277V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "aLB6MIiR277V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we want to do before we train our model is find a good learning rate."
      ],
      "metadata": {
        "id": "isT5v92S277V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = learner.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
        "\n",
        "learner.lr = learning_rates.valley\n",
        "\n",
        "f\"Learning Rate: {learner.lr}\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.093379Z",
          "iopub.status.idle": "2024-10-09T18:21:30.09374Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.093563Z",
          "shell.execute_reply": "2024-10-09T18:21:30.093582Z"
        },
        "trusted": true,
        "id": "69zwYv4w277V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Lets now freeze our model. What freezing does is that it prevents layers of our model from changing\n",
        "throughout the training process. This is very useful when we already have a pre-trained model whose existing\n",
        "knowledge we don't want to lose. With freezing we freeze the layers from top down and the final layers are\n",
        "free to learn the new segmentation task."
      ],
      "metadata": {
        "id": "xgH9vu4W277V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets freeze the top layers so that we don't lose some of the pre-trained\n",
        "# knowledge\n",
        "learner.freeze()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.095116Z",
          "iopub.status.idle": "2024-10-09T18:21:30.095456Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.095289Z",
          "shell.execute_reply": "2024-10-09T18:21:30.095306Z"
        },
        "trusted": true,
        "id": "iKnU29KV277V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set some callbacks for our model. One important callback is \"early stopping\"\n",
        "# which is a simple regularization technique we can use to stop training when\n",
        "# a specific metric, in this case the validation loss, stops improving.\n",
        "\n",
        "# TODO: Have SaveModelCallback use safetensor instead of unsafe pickle format\n",
        "callbacks: List[Callable] = [\n",
        "    ShowGraphCallback(),\n",
        "    EarlyStoppingCallback(),\n",
        "    SaveModelCallback(fname=\"/workspace/models/ai4mars_model\"),\n",
        "]\n",
        "\n",
        "if g_ENABLE_WANDB:\n",
        "    callbacks.append(WandbCallback())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.096798Z",
          "iopub.status.idle": "2024-10-09T18:21:30.097158Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.096982Z",
          "shell.execute_reply": "2024-10-09T18:21:30.097001Z"
        },
        "trusted": true,
        "id": "gDJb-V8g277W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, now we can train our model."
      ],
      "metadata": {
        "id": "vCJBq9Dq277W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleanup_gpu_cache()\n",
        "\n",
        "learner.fit_one_cycle(20, cbs=callbacks)\n",
        "\n",
        "cleanup_gpu_cache()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.098108Z",
          "iopub.status.idle": "2024-10-09T18:21:30.098456Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.098281Z",
          "shell.execute_reply": "2024-10-09T18:21:30.0983Z"
        },
        "trusted": true,
        "id": "Xpeca52h277W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets save the model to disk. Since we won’t be training the model further, we\n",
        "can ignore the optimizer and only save the model weights."
      ],
      "metadata": {
        "id": "9LDhbxWN277W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.save(\"/workspace/models/ai4mars_unet_resnet18\", with_opt=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.099717Z",
          "iopub.status.idle": "2024-10-09T18:21:30.100106Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.099928Z",
          "shell.execute_reply": "2024-10-09T18:21:30.099948Z"
        },
        "trusted": true,
        "id": "efPHIbbw277W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.recorder.plot_metrics()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.101165Z",
          "iopub.status.idle": "2024-10-09T18:21:30.101509Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.101332Z",
          "shell.execute_reply": "2024-10-09T18:21:30.101349Z"
        },
        "trusted": true,
        "id": "BRLpJJv0277W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.recorder.plot_sched()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.102427Z",
          "iopub.status.idle": "2024-10-09T18:21:30.102806Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.102608Z",
          "shell.execute_reply": "2024-10-09T18:21:30.102627Z"
        },
        "trusted": true,
        "id": "_doIHHK6277W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "aeB0QFq0277W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.show_results(max_n=4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.103948Z",
          "iopub.status.idle": "2024-10-09T18:21:30.104291Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.104116Z",
          "shell.execute_reply": "2024-10-09T18:21:30.104134Z"
        },
        "trusted": true,
        "id": "MD39tQFS277X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = SegmentationInterpretation.from_learner(learner)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.105324Z",
          "iopub.status.idle": "2024-10-09T18:21:30.105681Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.105506Z",
          "shell.execute_reply": "2024-10-09T18:21:30.105525Z"
        },
        "trusted": true,
        "id": "dCw80Kp3277X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.plot_top_losses(4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.106619Z",
          "iopub.status.idle": "2024-10-09T18:21:30.106989Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.106807Z",
          "shell.execute_reply": "2024-10-09T18:21:30.106829Z"
        },
        "trusted": true,
        "id": "mjFPABDe277X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Profile\n",
        "\n",
        "In this section we want to profile our trained model to get a good feel for how\n",
        "it will perform in the deployment environment."
      ],
      "metadata": {
        "id": "Lk4I1D3h277X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "test_image = PIL.Image.open(IMAGES_PATH_UNUSED.ls()[3]).resize(mask_sizes)\n",
        "test_image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.108858Z",
          "iopub.status.idle": "2024-10-09T18:21:30.109217Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.109041Z",
          "shell.execute_reply": "2024-10-09T18:21:30.109059Z"
        },
        "trusted": true,
        "id": "PqVuuvpR277X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = torchvision.transforms.functional.pil_to_tensor(test_image) / 255.0\n",
        "\n",
        "test_image.unsqueeze_(0)\n",
        "test_image.size()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.110556Z",
          "iopub.status.idle": "2024-10-09T18:21:30.111162Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.11097Z",
          "shell.execute_reply": "2024-10-09T18:21:30.110991Z"
        },
        "trusted": true,
        "id": "fGFXTreO277X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.112593Z",
          "iopub.status.idle": "2024-10-09T18:21:30.112974Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.112769Z",
          "shell.execute_reply": "2024-10-09T18:21:30.112807Z"
        },
        "trusted": true,
        "id": "eYLiKFkT277X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.eval();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.114268Z",
          "iopub.status.idle": "2024-10-09T18:21:30.114633Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.114447Z",
          "shell.execute_reply": "2024-10-09T18:21:30.114466Z"
        },
        "trusted": true,
        "id": "VhJgalcm277Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.to(\"cpu\")\n",
        "\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU], record_shapes=True, profile_memory=True\n",
        ") as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        learner.predict(IMAGES_PATH_UNUSED.ls()[3])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.116263Z",
          "iopub.status.idle": "2024-10-09T18:21:30.116606Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.116428Z",
          "shell.execute_reply": "2024-10-09T18:21:30.116446Z"
        },
        "trusted": true,
        "id": "0X6ZXjoj277Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    prof.key_averages(group_by_input_shape=True).table(\n",
        "        sort_by=\"cpu_time_total\", row_limit=10\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.117695Z",
          "iopub.status.idle": "2024-10-09T18:21:30.118069Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.117893Z",
          "shell.execute_reply": "2024-10-09T18:21:30.117912Z"
        },
        "trusted": true,
        "id": "xeeSF8DS277Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export"
      ],
      "metadata": {
        "id": "PXM_HR6Z277Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.export(\"/workspace/models/ai4mars_unet_resnet18.pkl\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.119805Z",
          "iopub.status.idle": "2024-10-09T18:21:30.120397Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.120116Z",
          "shell.execute_reply": "2024-10-09T18:21:30.120143Z"
        },
        "trusted": true,
        "id": "F64L07Lf277Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import ModelCard, ModelCardData"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.121538Z",
          "iopub.status.idle": "2024-10-09T18:21:30.122052Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.121773Z",
          "shell.execute_reply": "2024-10-09T18:21:30.121818Z"
        },
        "trusted": true,
        "id": "6nqx-pNS277Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "card_data = ModelCardData(\n",
        "    language=\"en\",\n",
        "    license=\"mit\",\n",
        "    library_name=\"fastai\",\n",
        "    datasets=[\"ai4mars_v0.1\"],\n",
        "    base_model=\"U-Net ResNet-18 Backbone\",\n",
        "    metrics=[\"mIoU\"],\n",
        ")\n",
        "\n",
        "card = ModelCard.from_template(\n",
        "    card_data,\n",
        "    model_id=\"ai4mars-unet-resnet18\",\n",
        "    model_description=\"semantic segmentation of the ai4mars terrain dataset\",\n",
        "    developers=\"Esteban Duran\",\n",
        "    repo=\"https://github.com/huggingface/huggingface_hub\",\n",
        ")\n",
        "card.save(\"/workspace/models/ai4mars_model_card.md\")\n",
        "print(card)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T18:21:30.123432Z",
          "iopub.status.idle": "2024-10-09T18:21:30.123945Z",
          "shell.execute_reply.started": "2024-10-09T18:21:30.123667Z",
          "shell.execute_reply": "2024-10-09T18:21:30.123694Z"
        },
        "trusted": true,
        "id": "kn6ihsKI277Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion and Future Work\n",
        "\n",
        "We have sucessfully trained a model that meets all of our requirements. It\n",
        "might not be the best and greatest but it works just fine under our constraints.\n",
        "\n",
        "For some future work, I'd like to throw out some of these constraints and\n",
        "explore what a state-of-the-art model would look like for this dataset. Perhaps\n",
        "a transformer architecture? Additionally, it would be great to explore how to\n",
        "use the data that was missing the labels. Perhaps we can manually label them,\n",
        "although it will take some time and having an expert would be better. Or, we\n",
        "could have a foundation model like SAM segment the image for us. Another\n",
        "interesting avenue is to explore deployment optimization techniques like\n",
        "quantization for efficient embedded device deployment.So many things to do!"
      ],
      "metadata": {
        "id": "AfCdouw7277Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "[1] AI4MARS: A dataset for Terrain-Aware autonomous driving on Mars. (2021, June 1). IEEE Conference Publication | IEEE Xplore. https://ieeexplore.ieee.org/document/9523149.\n",
        "\n",
        "[2] SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers. (2021, October 21). https://arxiv.org/abs/2105.15203v3.\n",
        "\n",
        "[2] Mish: A Self Regularized Non-Monotonic Activation Function. (2019, August 13). https://arxiv.org/abs/1908.08681"
      ],
      "metadata": {
        "id": "3QVcSB4R277Z"
      }
    }
  ]
}